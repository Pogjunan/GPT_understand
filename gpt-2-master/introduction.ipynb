{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def40ab2-a1fb-4d0f-ae8b-5e35e7c3b1b5",
   "metadata": {},
   "source": [
    "# GPT-2 from GPT-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce7d7b-6266-4209-adf1-30d57adb6299",
   "metadata": {},
   "source": [
    "we know how to operate `GPT-1`\n",
    "\n",
    "`Transformer` - `??`  - `GPT-1` - `GPT-2` - .. - `GPT-o3`\n",
    "I think to need filling `??` , so we have to learn from fromer papers.\n",
    "\n",
    "At least I understood Transformer paper during 2 month ,when i was 3 grad of statistics major and started self-teaching deeplearning during 1years.\n",
    "so today we have to leap next step which help to understand GPT-3 & GPT-o1 & GPT-o3..\n",
    "\n",
    "I surprised gpt-o3 get AGI so I can't delay any longer. study hard to understand and get yours. Develop and evolve based on what you have learned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65744d56-52fe-4c65-bb78-a0fec4ba6a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3cb53bc-639d-4d7a-8f24-d1ccc3d2084f",
   "metadata": {},
   "source": [
    "# `Transformer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87784be-1d71-404c-ac78-b9e81770c182",
   "metadata": {},
   "source": [
    "`Attention Is All You Need`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acfc18d-564a-4b46-8008-010088e355a3",
   "metadata": {},
   "source": [
    "`Abstract`\n",
    "\n",
    "`Introduction`\n",
    "\n",
    "`Background`\n",
    "\n",
    "`Model Architecture`\n",
    "\n",
    "`Encoder and Decoder Stacks`\n",
    "\n",
    "`Attention`\n",
    "\n",
    "`Scaled Dot-Product Attention`\n",
    "\n",
    "`Multi-Head Attention`\n",
    "\n",
    "`Applications of Attention in our Model`\n",
    "\n",
    "`Position-wise Feed-Forward Networks`\n",
    "\n",
    "`Embeddings and Softmax`\n",
    "\n",
    "`Positional Encoding`\n",
    "\n",
    "`Why Self-Attention`\n",
    "\n",
    "\n",
    "` Training`\n",
    "\n",
    "`Optimizer`\n",
    "\n",
    "`Regularization`\n",
    "\n",
    "\n",
    "`Results`\n",
    "`Machine Translation`\n",
    "`English Constituency Parsing`\n",
    "\n",
    "` Conclusion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea905b74-b215-4fad-aab6-1f857eb2c6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deep)",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
